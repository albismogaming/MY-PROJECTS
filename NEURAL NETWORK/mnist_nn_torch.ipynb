{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.9160\n",
      "Epoch 2, Loss: 0.6542\n",
      "Epoch 3, Loss: 0.6075\n",
      "Epoch 4, Loss: 0.5816\n",
      "Epoch 5, Loss: 0.5687\n",
      "Epoch 6, Loss: 0.5594\n",
      "Epoch 7, Loss: 0.5534\n",
      "Epoch 8, Loss: 0.5468\n",
      "Epoch 9, Loss: 0.5421\n",
      "Epoch 10, Loss: 0.5394\n",
      "Epoch 11, Loss: 0.5372\n",
      "Epoch 12, Loss: 0.5327\n",
      "Epoch 13, Loss: 0.5315\n",
      "Epoch 14, Loss: 0.5282\n",
      "Epoch 15, Loss: 0.5263\n",
      "Epoch 16, Loss: 0.5243\n",
      "Epoch 17, Loss: 0.5246\n",
      "Epoch 18, Loss: 0.5223\n",
      "Epoch 19, Loss: 0.5205\n",
      "Epoch 20, Loss: 0.5225\n",
      "Epoch 21, Loss: 0.5160\n",
      "Epoch 22, Loss: 0.5211\n",
      "Epoch 23, Loss: 0.5168\n",
      "Epoch 24, Loss: 0.5167\n",
      "Training Complete!\n",
      "Test Accuracy: 98.28%\n"
     ]
    }
   ],
   "source": [
    "# Define transformations (Convert images to tensors & Normalize)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize to [-1,1]\n",
    "])\n",
    "\n",
    "# Load train and test sets\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False)\n",
    "\n",
    "class MNIST_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNIST_Net, self).__init__()\n",
    "        \n",
    "        # Input Layer\n",
    "        self.fc1 = nn.Linear(28 * 28, 256)  # First hidden layer (more neurons)\n",
    "        \n",
    "        # Hidden Layers (Added more layers)\n",
    "        self.fc2 = nn.Linear(256, 128)  \n",
    "        self.fc3 = nn.Linear(128, 64)  \n",
    "        self.fc4 = nn.Linear(64, 32)   # New hidden layer\n",
    "        self.fc5 = nn.Linear(32, 10)   # Output layer (still 10 for digits 0-9)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.3)  # Add dropout to prevent overfitting\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)  # Flatten image\n",
    "        \n",
    "        # Forward pass with ReLU activations\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))  # New layer activation\n",
    "        x = self.fc5(x)          # No activation on final layer (logits)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = MNIST_Net()\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 24\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader):.4f}\")\n",
    "\n",
    "print(\"Training Complete!\")\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# No gradient tracking needed during evaluation\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)  # Get predicted class\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get a single batch of test images\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Select a random image from the batch\n",
    "index = np.random.randint(0, len(images))  # Random index\n",
    "image = images[index]  # Select the image\n",
    "true_label = labels[index].item()  # True label\n",
    "\n",
    "# Set model to evaluation mode and make a prediction\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(image.unsqueeze(0))  # Add batch dimension\n",
    "    _, predicted_label = torch.max(output, 1)  # Get highest probability index\n",
    "\n",
    "predicted_label = predicted_label.item()  # Convert tensor to int\n",
    "\n",
    "# Plot the image with the predicted label\n",
    "plt.imshow(image.squeeze(), cmap=\"gray\")\n",
    "plt.title(f\"Predicted: {predicted_label} | Actual: {true_label}\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
